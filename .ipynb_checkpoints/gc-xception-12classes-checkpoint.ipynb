{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Garbage Classification using keras and transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel shows how to classify Garbage images into 12 different classes using transfer learning. I also created a webapp that can classify garbage images based on the model trained here, fell free to play a bit with it! https://mostafa-portfolio.azurewebsites.net/ .If you find this kernel useful please upvote it!\n",
    "\n",
    "Transfer learning means that instead of your model learning everything from scratch, it uses another model that was trained on a similar problem, so that you can \"transfer\" the learned \"knowledge\" of the pretrained model to your model, and then learn some new features.\n",
    "\n",
    "The ImageNet Data set is huge data set consisting of more than 14 million images from more than 22,000 different categories, here we are using a smaller version of it which has 1000 different categories.\n",
    "\n",
    "In this kernel we use an xception model which is pretrained on the ImageNet dataset and then build some layers on top of it to be able to classify the garbage images.\n",
    "\n",
    "Transfer learning makes sense here because the ImageNet data set has a much larger number of images (14 million) than the Garbage Classification data set (around 15,500 image). This increases the speed of training for our model and the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T05:59:38.515013Z",
     "start_time": "2021-04-15T05:59:26.141175Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-803db8cf3b3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.experimental'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras.applications.xception as xception\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras.layers.experimental.preprocessing import Normalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('setup successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T05:59:38.516990Z",
     "start_time": "2021-04-15T05:59:38.285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Increasing the image size didn't result in increasing the training accuracy\n",
    "IMAGE_WIDTH = 320    \n",
    "IMAGE_HEIGHT = 320\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "\n",
    "# Path where our data is located\n",
    "base_path = \"../input/garbage-classification/garbage_classification/\"\n",
    "\n",
    "# Dictionary to save our 12 classes\n",
    "categories = {0: 'paper', 1: 'cardboard', 2: 'plastic', 3: 'metal', 4: 'trash', 5: 'battery',\n",
    "              6: 'shoes', 7: 'clothes', 8: 'green-glass', 9: 'brown-glass', 10: 'white-glass',\n",
    "              11: 'biological'}\n",
    "\n",
    "print('defining constants successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a data frame that has in one column the filenames of all our images and in the other column the corresponding category. \n",
    "We Open the directories in the dataset one by one, save the filenames in the filenames_list and add the corresponding category in the categories_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class name prefix to filename. So for example \"/paper104.jpg\" become \"paper/paper104.jpg\"\n",
    "def add_class_name_prefix(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(lambda x: x[:re.search(\"\\d\",x).start()] + '/' + x)\n",
    "    return df\n",
    "\n",
    "# list conatining all the filenames in the dataset\n",
    "filenames_list = []\n",
    "# list to store the corresponding category, note that each folder of the dataset has one class of data\n",
    "categories_list = []\n",
    "\n",
    "for category in categories:\n",
    "    filenames = os.listdir(base_path + categories[category])\n",
    "    \n",
    "    filenames_list = filenames_list  +filenames\n",
    "    categories_list = categories_list + [category] * len(filenames)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames_list,\n",
    "    'category': categories_list\n",
    "})\n",
    "\n",
    "df = add_class_name_prefix(df, 'filename')\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('number of elements = ' , len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see sample image, you can run the same cell again to get a different image\n",
    "random_row = random.randint(0, len(df)-1)\n",
    "sample = df.iloc[random_row]\n",
    "randomimage = image.load_img(base_path +sample['filename'])\n",
    "print(sample['filename'])\n",
    "plt.imshow(randomimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viusalize the Categories Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization = df.copy()\n",
    "# Change the catgegories from numbers to names\n",
    "df_visualization['category'] = df_visualization['category'].apply(lambda x:categories[x] )\n",
    "\n",
    "df_visualization['category'].value_counts().plot.bar(x = 'count', y = 'category' )\n",
    "\n",
    "plt.xlabel(\"Garbage Classes\", labelpad=14)\n",
    "plt.ylabel(\"Images Count\", labelpad=14)\n",
    "plt.title(\"Count of images per class\", y=1.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps are:\n",
    "1. Create an xception model without the last layer and load the ImageNet pretrained weights\n",
    "2. Add a pre-processing layer\n",
    "3. Add a pooling layer followed by a softmax layer at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "import keras.applications.xception as xception\n",
    "\n",
    "xception_layer = xception.Xception(include_top = False, input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS),\n",
    "                       weights = '../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# We don't want to train the imported weights\n",
    "xception_layer.trainable = False\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "\n",
    "#create a custom layer to apply the preprocessing\n",
    "def xception_preprocessing(img):\n",
    "  return xception.preprocess_input(img)\n",
    "\n",
    "model.add(Lambda(xception_preprocessing))\n",
    "\n",
    "model.add(xception_layer)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(Dense(len(categories), activation='softmax')) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the EarlyStopping call back to stop our training if the validation_accuray is not improving for a certain number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience = 2, verbose = 1, monitor='val_categorical_accuracy' , mode='max', min_delta=0.001, restore_best_weights = True)\n",
    "\n",
    "callbacks = [early_stop]\n",
    "\n",
    "print('call back defined!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the training set into three separate sets:\n",
    "\n",
    "1. **The training set:** used to train our model.\n",
    "1. **The validation set**: used to double check that our model is not overfitting the training set, i.e. it can also generalise to other data other than the train data\n",
    "1. **The Test set:** Used to estimate the accuracy of the model on new data other than the ones the model used for training\n",
    "For a competition  or for some other cases, you can split the data only to training and validation sets in order to achieve the highest  possible accuracy, without the need to properly estimate how accurate the model really is.\n",
    "\n",
    "We split the data set as follows: 80% train set, 10% cross_validation set, and 10% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the categories from numbers to names\n",
    "df[\"category\"] = df[\"category\"].replace(categories) \n",
    "\n",
    "# We first split the data into two sets and then split the validate_df to two sets\n",
    "train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "validate_df, test_df = train_test_split(validate_df, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "print('train size = ', total_validate , 'validate size = ', total_validate, 'test size = ', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create the training data generator, that will get the images from the input data directory to train on them. We will also create a generator for the validation set.\n",
    "\n",
    "Applying Data Augmentation on the training set was taking too long to be executed and the initial results didn't show much improvement than the results without augmentation, so I commented the augmentation to make the training faster. However fell free to uncomment the Data Augmentation lines in the following cell and play a bit with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    \n",
    "    ###  Augmentation Start  ###\n",
    "    \n",
    "    #rotation_range=30,\n",
    "    #shear_range=0.1,\n",
    "    #zoom_range=0.3,\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip = True,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2\n",
    "    \n",
    "    ##  Augmentation End  ###\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = image.ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_yticks(np.arange(0, 0.7, 0.1))\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "legend = plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model we will create a test generator to load the images from the input data directory and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = image.ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe= test_df,\n",
    "    directory=base_path,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=1,\n",
    "    shuffle=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "_, accuracy = model.evaluate_generator(test_generator, nb_samples)\n",
    "\n",
    "print('accuracy on test set = ',  round((accuracy * 100),2 ), '% ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, the accuracy is well over 90% !! (it varies from one run to another due to the random shuffling but is between 94% and 96%) \n",
    "\n",
    "But let's have a look on the F1 score for each of the categories. For that we will be using the classification_report from the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We defined at the beginning of this notebook a dictionary that maps the categories number to names, but the train generator\n",
    "# generated it's own dictionary and it has assigned different numbers to our categories and the predictions made by the model \n",
    "# will be made using the genrator's dictionary.\n",
    "\n",
    "gen_label_map = test_generator.class_indices\n",
    "gen_label_map = dict((v,k) for k,v in gen_label_map.items())\n",
    "print(gen_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model's predictions for the test set\n",
    "preds = model.predict_generator(test_generator, nb_samples)\n",
    "\n",
    "# Get the category with the highest predicted probability, the prediction is only the category's number and not name\n",
    "preds = preds.argmax(1)\n",
    "\n",
    "# Convert the predicted category's number to name \n",
    "preds = [gen_label_map[item] for item in preds]\n",
    "\n",
    "# Convert the pandas dataframe to a numpy matrix\n",
    "labels = test_df['category'].to_numpy()\n",
    "\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows among other info the F1 score of each category. In the bottom of the F1 score column notice two numbers accuracy and macro avg. Accuracy is the same accuracy that we evaluated above for the test set, it is a weighted average. \n",
    "\n",
    "However the macro avg (unweighted average) is a bit less than accuracy. This is because the clothes category, the category which has by far the largest number of images, has a very high F1 score, so accuracy (the weighted average) is higher than the unweighted average (macro avg).\n",
    "\n",
    "For this problem I would consider the macro avg a better measure of accuracy as it takes an average of all the F1 scores regardless of how much data we have in the training data for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you liked this kernel please upvote! I also created a small web app to classify the garbage images, https://mostafa-portfolio.azurewebsites.net/ feel free to play around with it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
